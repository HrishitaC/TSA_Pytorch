{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TSA_PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UqAMIUmtAx1U",
        "sEVwHGUSA5HN",
        "WT-PhWzyBJ4S",
        "FY1uXAQKNDXm",
        "g-bMEs_LwMh0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07de4e707cf24210949dbb346913ccff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eb96de0b40484d9e96b1268059fabdd1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cf5428acc5b440fad4f555607f2c289",
              "IPY_MODEL_e8dc6b9a595440fea188da0133498b88"
            ]
          }
        },
        "eb96de0b40484d9e96b1268059fabdd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cf5428acc5b440fad4f555607f2c289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_809e8390149945da8b7a966214396970",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_931b4350bd224508981cb0db6ced7d19"
          }
        },
        "e8dc6b9a595440fea188da0133498b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9f043c4319bf4def8d14a17ba00c4b36",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 579kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d62a48f24ba74c60832d2c1b8babf7a3"
          }
        },
        "809e8390149945da8b7a966214396970": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "931b4350bd224508981cb0db6ced7d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f043c4319bf4def8d14a17ba00c4b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d62a48f24ba74c60832d2c1b8babf7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cb58a4e5f7a84df8ab6284b2b0195f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae13b50d861345198a4f9dbc7a67cc33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_180d36bb81ea4a8f8d91a74d1026bce0",
              "IPY_MODEL_b0112b629b5e4d65af74e93a8b67564f"
            ]
          }
        },
        "ae13b50d861345198a4f9dbc7a67cc33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "180d36bb81ea4a8f8d91a74d1026bce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0677de77fe6b41e681f72d3f01058f88",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1be6303ca07f4f44b6c4afc522606a70"
          }
        },
        "b0112b629b5e4d65af74e93a8b67564f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_753ee99e8f464d7980685ee01475b789",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:12&lt;00:00, 33.7B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_147acac239124caaa8255c299c69a732"
          }
        },
        "0677de77fe6b41e681f72d3f01058f88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1be6303ca07f4f44b6c4afc522606a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "753ee99e8f464d7980685ee01475b789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "147acac239124caaa8255c299c69a732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b60b8717184d4316b85c0f589f2c0852": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3555afcc5f674c17ac908d7fb57cdb51",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_59783fee81df475397fbb470bed3ce03",
              "IPY_MODEL_3a198cd973c64ecf9643ab8d519fe4db"
            ]
          }
        },
        "3555afcc5f674c17ac908d7fb57cdb51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59783fee81df475397fbb470bed3ce03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_35ce995315e245509c6c2c02cbab0224",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cc7a03f8b50482b8780100a2210b664"
          }
        },
        "3a198cd973c64ecf9643ab8d519fe4db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb01d4aa75214b54a695dc04715131ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:12&lt;00:00, 34.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2539b02b9a8345d9ba86864740667b9b"
          }
        },
        "35ce995315e245509c6c2c02cbab0224": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cc7a03f8b50482b8780100a2210b664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb01d4aa75214b54a695dc04715131ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2539b02b9a8345d9ba86864740667b9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqAMIUmtAx1U",
        "colab_type": "text"
      },
      "source": [
        "#Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRgh7tW5uPUn",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "5d77ff85-3d20-4423-f21c-f7e875a1497f"
      },
      "source": [
        "#uploading kaggle file\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-323988e2-2b33-4720-9287-0c30a4b5f7dc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-323988e2-2b33-4720-9287-0c30a4b5f7dc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlGHqqmjOx2-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7fe6b1fc-322f-4d9b-bd84-eb32686a8075"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.6.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp7aIdR9O0DP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQd3nMBcPLNs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "627ffe0c-7642-4737-c86d-df07c397058a"
      },
      "source": [
        "!kaggle competitions download -c sentiment-analysis-of-tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test_samples.txt to /content\n",
            "  0% 0.00/714k [00:00<?, ?B/s]\n",
            "100% 714k/714k [00:00<00:00, 48.6MB/s]\n",
            "Downloading train.txt.zip to /content\n",
            "  0% 0.00/1.36M [00:00<?, ?B/s]\n",
            "100% 1.36M/1.36M [00:00<00:00, 92.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSnnE70tPPJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b738fe5-c06c-45a0-d3cb-50042874e08b"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "filename = \"train.txt.zip\"\n",
        "\n",
        "with ZipFile(filename, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "821UFhBmuVhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c68d761d-18fa-431f-a9ce-88f03c025e16"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data_path = \"/content/train.txt\"\n",
        "\n",
        "\n",
        "tweet_data = pd.read_csv(train_data_path, sep=',')\n",
        "tweet_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264183816548130816</td>\n",
              "      <td>positive</td>\n",
              "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263405084770172928</td>\n",
              "      <td>negative</td>\n",
              "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262163168678248449</td>\n",
              "      <td>negative</td>\n",
              "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>264249301910310912</td>\n",
              "      <td>negative</td>\n",
              "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262682041215234048</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...                                         tweet_text\n",
              "0  264183816548130816  ...  Gas by my house hit $3.39!!!! I\\u2019m going t...\n",
              "1  263405084770172928  ...  Theo Walcott is still shit\\u002c watch Rafa an...\n",
              "2  262163168678248449  ...  its not that I\\u2019m a GSP fan\\u002c i just h...\n",
              "3  264249301910310912  ...  Iranian general says Israel\\u2019s Iron Dome c...\n",
              "4  262682041215234048  ...  Tehran\\u002c Mon Amour: Obama Tried to Establi...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW9lc0m9upGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "def cleaning_tweets(tweets):\n",
        "  cleaned_tweets = []\n",
        "  \n",
        "  for tweet in tweets:\n",
        "    tweet = re.sub(\"#\",\"\",tweet) #removing hashtags but retaining the hashtag content\n",
        "    tweet = re.sub(\"@\\S+\", \"\", tweet) #removing tagged usernames\n",
        "    for punc in punctuation:\n",
        "      tweet = tweet.replace(punc, \"\") #removing punctuations (have to find a way to avoid removinf emoticons)\n",
        "    tweet = re.sub(\"u\\d{3}.\", \"\", tweet) #removing UNIcodes\n",
        "    tweet = re.sub(\"http\\S*\", \"\", tweet) #removing hyperlinks\n",
        "    tweet = re.sub(\"\\d\", \"\", tweet) #removing numbers\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    cleaned_tweets.append(tweet)\n",
        "  \n",
        "  return cleaned_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KT_Afw_9gJZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eef7825c-3326-4c9c-e509-fe77bd1d82ff"
      },
      "source": [
        "tweet_data[\"cleaned_tweet\"] = cleaning_tweets(tweet_data.loc[:,\"tweet_text\"])\n",
        "tweet_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264183816548130816</td>\n",
              "      <td>positive</td>\n",
              "      <td>Gas by my house hit $3.39!!!! I\\u2019m going t...</td>\n",
              "      <td>gas by my house hit  im going to chapel hill o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>263405084770172928</td>\n",
              "      <td>negative</td>\n",
              "      <td>Theo Walcott is still shit\\u002c watch Rafa an...</td>\n",
              "      <td>theo walcott is still shit watch rafa and john...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>262163168678248449</td>\n",
              "      <td>negative</td>\n",
              "      <td>its not that I\\u2019m a GSP fan\\u002c i just h...</td>\n",
              "      <td>its not that im a gsp fan i just hate nick dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>264249301910310912</td>\n",
              "      <td>negative</td>\n",
              "      <td>Iranian general says Israel\\u2019s Iron Dome c...</td>\n",
              "      <td>iranian general says israels iron dome cant de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>262682041215234048</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Tehran\\u002c Mon Amour: Obama Tried to Establi...</td>\n",
              "      <td>tehran mon amour obama tried to establish ties...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...                                      cleaned_tweet\n",
              "0  264183816548130816  ...  gas by my house hit  im going to chapel hill o...\n",
              "1  263405084770172928  ...  theo walcott is still shit watch rafa and john...\n",
              "2  262163168678248449  ...  its not that im a gsp fan i just hate nick dia...\n",
              "3  264249301910310912  ...  iranian general says israels iron dome cant de...\n",
              "4  262682041215234048  ...  tehran mon amour obama tried to establish ties...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc3mjDEcGnCS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "label_counts = Counter(tweet_data.loc[:,\"sentiment\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nhXlG0tyZvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de8da408-7c1c-4ace-f467-359a3bd412f0"
      },
      "source": [
        "label_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 3387, 'neutral': 9014, 'positive': 9064})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEVwHGUSA5HN",
        "colab_type": "text"
      },
      "source": [
        "#Model 1: Simple RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z337F11boXLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "bs = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wau6aV5JLs3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Field, LabelField\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "text_field = Field(tokenize='spacy')\n",
        "\n",
        "label_field = LabelField()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlVhD0VmDyRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "59a7b2aa-3a56-4c05-9597-21734fea0d74"
      },
      "source": [
        "df = tweet_data.loc[:,['cleaned_tweet', 'sentiment']]\n",
        "\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gas house hit going chapel hill sat happy</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>theo walcott still shit watch rafa johnny deal...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not gsp fan hate nick diaz cant wait february</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iranian general says israels iron dome cant de...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tehran mon amour obama tried establish ties mu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sat whole movie harry ron christmas ohlawd</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>davlar main rivals team poland hopefully make ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>talking acts sats deciding want college applyi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>why happy valentines day trending its february...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>they may superbowl dallas dallas aint winning ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       cleaned_tweet sentiment\n",
              "0          gas house hit going chapel hill sat happy  positive\n",
              "1  theo walcott still shit watch rafa johnny deal...  negative\n",
              "2      not gsp fan hate nick diaz cant wait february  negative\n",
              "3  iranian general says israels iron dome cant de...  negative\n",
              "4  tehran mon amour obama tried establish ties mu...   neutral\n",
              "5         sat whole movie harry ron christmas ohlawd   neutral\n",
              "6  davlar main rivals team poland hopefully make ...  positive\n",
              "7  talking acts sats deciding want college applyi...  negative\n",
              "8  why happy valentines day trending its february...   neutral\n",
              "9  they may superbowl dallas dallas aint winning ...  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bde-UiUlEBI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Dataset, Example\n",
        "\n",
        "# Torchtext does not have any inherit method to deal with dataframes\n",
        "# as input data, hence we create a child class of Dataset class  \n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns-whd3KEQiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', text_field),\n",
        "        ('label', label_field)\n",
        "    )\n",
        ").split(split_ratio=0.8) #creating dataset and splitting it into train and validation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czQoYuSTEcBj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "eceb759b-9529-4c76-c595-5c766bb247b2"
      },
      "source": [
        "print(\"train_data example: \",vars(train_data.examples[0]))\n",
        "print(\"valid_data example: \",vars(valid_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data example:  {'text': ['career', 'fair', 'tomorrow', 'murphy', 'center', 'dress', 'business', 'attire', 'bring', 'resumes'], 'label': 'neutral'}\n",
            "valid_data example:  {'text': ['ill', 'share', 'care', 'clud', 'weird', 'crush', 'justin', 'sororithank', 'you', 'gin', 'real', 'life', 'comes', 'across', 'turn'], 'label': 'negative'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_zNVG3hEojB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "be4daba0-7b30-4c78-9a36-c6fe81d43c1b"
      },
      "source": [
        "print('No of training examples:', len(train_data))\n",
        "print('No of validation examples:', len(valid_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of training examples: 17172\n",
            "No of validation examples: 4293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91D2a9-DcV0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB = 25000\n",
        "\n",
        "text_field.build_vocab(train_data, max_size = MAX_VOCAB) #all embeddings will be initialised with zero\n",
        "label_field.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4B28UQt8fEs7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4779d8ab-0ceb-4aa2-ee6e-ea37d9b66bda"
      },
      "source": [
        "text_field.vocab.freqs.most_common(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tomorrow', 2741),\n",
              " ('may', 2284),\n",
              " ('you', 1727),\n",
              " ('day', 1402),\n",
              " ('the', 1295),\n",
              " ('going', 1229),\n",
              " ('nt', 1220),\n",
              " ('night', 1163),\n",
              " ('not', 1094),\n",
              " ('see', 990),\n",
              " ('friday', 987),\n",
              " ('like', 939),\n",
              " ('time', 936),\n",
              " ('game', 912),\n",
              " ('saturday', 867),\n",
              " ('happy', 865),\n",
              " ('get', 858),\n",
              " ('sunday', 856),\n",
              " ('new', 736),\n",
              " ('s', 719)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UysVedMs8ZSk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "39972a4d-ecd2-476a-df07-2d37821de27f"
      },
      "source": [
        "len(text_field.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mnjvSu4Zlmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "from torchtext.data import BucketIterator\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device,\n",
        "    sort_key= lambda x: len(x.text),\n",
        "    sort_within_batch = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAIVNNmspF-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, ip_dim, emb_dim, hid_dim, op_dim):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(ip_dim, emb_dim)\n",
        "    self.rnn = nn.RNN(emb_dim, hid_dim)\n",
        "    self.fc = nn.Linear(hid_dim, op_dim)\n",
        "\n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)\n",
        "    output, hidden = self.rnn(embedded)\n",
        "\n",
        "    assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
        "\n",
        "    return self.fc(hidden.squeeze(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocgVfYyVrJyD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(text_field.vocab)\n",
        "emb_dim = 100\n",
        "hidden_dim = 256\n",
        "out_dim = len(label_field.vocab)\n",
        "\n",
        "model = RNN(input_dim, emb_dim, hidden_dim, out_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1EuXSkLL7jn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3bab602e-d660-47c1-fb4c-64f478ef335f"
      },
      "source": [
        "def num_params(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"The model has {num_params(model):,} trainable params\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,592,619 trainable params\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omirHaS8MSqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CqqyxlUnJ7S4",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijk6vx95Mmz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0o1PzUnMJ7S8",
        "colab": {}
      },
      "source": [
        "def calc_acc(preds, y):\n",
        "  max_preds = preds.argmax(dim=1, keepdim = True)\n",
        "  correct = max_preds.squeeze(1).eq(y)\n",
        "  return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVd7v5ROM-WL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = calc_acc(predictions, batch.label)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A03UYP9GX5m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion): \n",
        "  \"\"\"\n",
        "  Used for testing purposed hence no backprop\n",
        "  Also the dropout and BatchNorm layers are deactivated in model.eval()\n",
        "  \"\"\"\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      predictions = model(batch.text).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      acc = calc_acc(predictions, batch.label)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "    return epoch_loss/len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1HO_Ya-Ytzl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time/60)\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins*60))\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq6ymfgXZLkJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb3d0051-e96e-4485-c51e-ddf6f208ea8e"
      },
      "source": [
        "epochs = 300 \n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'phase-1.pt')\n",
        "\n",
        "  if ((epoch + 1) % 10 == 0) or (epoch == 0):\n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.025 | Train Acc: 42.19%\n",
            "\tVal. Loss: 1.108 | Val. Acc: 32.83%\n",
            "Epoch: 10 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.018 | Train Acc: 42.03%\n",
            "\tVal. Loss: 1.101 | Val. Acc: 33.49%\n",
            "Epoch: 20 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.018 | Train Acc: 42.28%\n",
            "\tVal. Loss: 1.095 | Val. Acc: 35.01%\n",
            "Epoch: 30 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.018 | Train Acc: 42.15%\n",
            "\tVal. Loss: 1.090 | Val. Acc: 35.68%\n",
            "Epoch: 40 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.017 | Train Acc: 42.56%\n",
            "\tVal. Loss: 1.085 | Val. Acc: 36.93%\n",
            "Epoch: 50 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.018 | Train Acc: 42.99%\n",
            "\tVal. Loss: 1.079 | Val. Acc: 37.76%\n",
            "Epoch: 60 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.017 | Train Acc: 42.74%\n",
            "\tVal. Loss: 1.075 | Val. Acc: 38.64%\n",
            "Epoch: 70 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.017 | Train Acc: 42.58%\n",
            "\tVal. Loss: 1.072 | Val. Acc: 39.03%\n",
            "Epoch: 80 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.017 | Train Acc: 42.81%\n",
            "\tVal. Loss: 1.069 | Val. Acc: 39.78%\n",
            "Epoch: 90 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.016 | Train Acc: 43.15%\n",
            "\tVal. Loss: 1.066 | Val. Acc: 40.57%\n",
            "Epoch: 100 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.017 | Train Acc: 42.90%\n",
            "\tVal. Loss: 1.063 | Val. Acc: 41.02%\n",
            "Epoch: 110 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.016 | Train Acc: 42.24%\n",
            "\tVal. Loss: 1.060 | Val. Acc: 41.92%\n",
            "Epoch: 120 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.016 | Train Acc: 42.86%\n",
            "\tVal. Loss: 1.058 | Val. Acc: 42.28%\n",
            "Epoch: 130 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.016 | Train Acc: 42.54%\n",
            "\tVal. Loss: 1.055 | Val. Acc: 42.67%\n",
            "Epoch: 140 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.015 | Train Acc: 43.45%\n",
            "\tVal. Loss: 1.054 | Val. Acc: 43.13%\n",
            "Epoch: 150 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.015 | Train Acc: 42.70%\n",
            "\tVal. Loss: 1.051 | Val. Acc: 43.30%\n",
            "Epoch: 160 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.016 | Train Acc: 42.49%\n",
            "\tVal. Loss: 1.049 | Val. Acc: 43.30%\n",
            "Epoch: 170 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.015 | Train Acc: 43.23%\n",
            "\tVal. Loss: 1.048 | Val. Acc: 43.25%\n",
            "Epoch: 180 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.015 | Train Acc: 43.31%\n",
            "\tVal. Loss: 1.046 | Val. Acc: 43.34%\n",
            "Epoch: 190 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.014 | Train Acc: 43.16%\n",
            "\tVal. Loss: 1.044 | Val. Acc: 43.80%\n",
            "Epoch: 200 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.013 | Train Acc: 43.55%\n",
            "\tVal. Loss: 1.042 | Val. Acc: 44.24%\n",
            "Epoch: 210 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.013 | Train Acc: 43.77%\n",
            "\tVal. Loss: 1.041 | Val. Acc: 44.08%\n",
            "Epoch: 220 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 1.012 | Train Acc: 43.49%\n",
            "\tVal. Loss: 1.039 | Val. Acc: 44.31%\n",
            "Epoch: 230 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.011 | Train Acc: 43.79%\n",
            "\tVal. Loss: 1.035 | Val. Acc: 44.70%\n",
            "Epoch: 240 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.007 | Train Acc: 44.40%\n",
            "\tVal. Loss: 1.032 | Val. Acc: 44.70%\n",
            "Epoch: 250 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 1.001 | Train Acc: 45.63%\n",
            "\tVal. Loss: 1.028 | Val. Acc: 44.81%\n",
            "Epoch: 260 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.998 | Train Acc: 45.64%\n",
            "\tVal. Loss: 1.026 | Val. Acc: 44.88%\n",
            "Epoch: 270 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.992 | Train Acc: 46.77%\n",
            "\tVal. Loss: 1.027 | Val. Acc: 45.13%\n",
            "Epoch: 280 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.991 | Train Acc: 47.29%\n",
            "\tVal. Loss: 1.028 | Val. Acc: 45.27%\n",
            "Epoch: 290 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.985 | Train Acc: 48.36%\n",
            "\tVal. Loss: 1.025 | Val. Acc: 46.09%\n",
            "Epoch: 300 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.979 | Train Acc: 49.16%\n",
            "\tVal. Loss: 1.025 | Val. Acc: 46.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q29RCfNeBW1Q",
        "colab_type": "text"
      },
      "source": [
        "Phase1: Validation accuracy: 46.51%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT-PhWzyBJ4S",
        "colab_type": "text"
      },
      "source": [
        "#Model 2: Pretrained word embeddings and bidirectional RNN with LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFJEokI0o61d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "tokenizer = TweetTokenizer(strip_handles = True, reduce_len = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E3bMTDPrbQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "id = data.Field()\n",
        "tweet = data.Field(tokenize = tokenizer.tokenize, include_lengths = True) #tweet will be a tuple ([tokes], len(tweet))\n",
        "label = data.LabelField()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xr2ujje7qQk4",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Dataset, Example\n",
        "import pandas as pd\n",
        "\n",
        "# Torchtext does not have any inherit method to deal with dataframes\n",
        "# as input data, hence we create a child class of Dataset class  \n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL4IEnoSy8f-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "be1a86ef-9c11-4c95-c2e5-b170537f0709"
      },
      "source": [
        "df = tweet_data.loc[:,[\n",
        "                       #'tweet_id',\n",
        "                       'cleaned_tweet', \n",
        "                       'sentiment'\n",
        "                       ]]\n",
        "\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gas by my house hit  im going to chapel hill o...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>theo walcott is still shit watch rafa and john...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>its not that im a gsp fan i just hate nick dia...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iranian general says israels iron dome cant de...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tehran mon amour obama tried to establish ties...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>i sat through this whole movie just for harry ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>with j davlar th main rivals are team poland h...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>talking about acts  sats deciding where i want...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>why is happy valentines day trending its on th...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>they may have a superbowl in dallas but dallas...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       cleaned_tweet sentiment\n",
              "0  gas by my house hit  im going to chapel hill o...  positive\n",
              "1  theo walcott is still shit watch rafa and john...  negative\n",
              "2  its not that im a gsp fan i just hate nick dia...  negative\n",
              "3  iranian general says israels iron dome cant de...  negative\n",
              "4  tehran mon amour obama tried to establish ties...   neutral\n",
              "5  i sat through this whole movie just for harry ...   neutral\n",
              "6  with j davlar th main rivals are team poland h...  positive\n",
              "7  talking about acts  sats deciding where i want...  negative\n",
              "8  why is happy valentines day trending its on th...   neutral\n",
              "9  they may have a superbowl in dallas but dallas...  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pi3hemJxqQlA",
        "colab": {}
      },
      "source": [
        "import random\n",
        "\n",
        "train_data, valid_data = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        # ('id', id),\n",
        "        ('text', tweet),\n",
        "        ('label', label)\n",
        "    ),\n",
        ").split(split_ratio=0.8, random_state = random.getstate()) #creating dataset and splitting it into train and validation data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGUfkF4KMTT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "e0caccef-9e49-4abe-e706-a31340df3642"
      },
      "source": [
        "print(vars(train_data.examples[0]))\n",
        "print(vars(valid_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['can', 'it', 'please', 'be', 'wednesday', 'and', 'potus', 'has', 'been', 're', 'elected', 'then', 'we', 'can', 'move', 'this', 'country', 'forward'], 'label': 'neutral'}\n",
            "{'text': ['remembering', 'that', 'time', 'i', 'said', 'may', 'the', 'force', 'be', 'with', 'you', 'to', 'buzz', 'lightyear', 'at', 'disneyland', 'toinfinitiandbeyond'], 'label': 'positive'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1L4EC9aQFxZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "97fa06de-c840-481d-9bbd-13163000c57a"
      },
      "source": [
        "# max_vocab_size = 25000\n",
        "\n",
        "#using pretrained embeddings\n",
        "tweet.build_vocab(train_data,\n",
        "                  # max_size = max_vocab_size,\n",
        "                  vectors = \"glove.twitter.27B.100d\",\n",
        "                  unk_init = torch.Tensor.normal_) # in case a word is not present in the pretrained embedding, it will be assigned a random value from normal distribution, instead of zero\n",
        "\n",
        "label.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.twitter.27B.zip: 1.52GB [11:44, 2.16MB/s]                            \n",
            "100%|█████████▉| 1193334/1193514 [01:07<00:00, 18263.50it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Opzrpc_OngM0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d3332cc-f0a7-4ea9-ee54-2a6e3455148a"
      },
      "source": [
        "print(len(tweet.vocab))\n",
        "print(len(label.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25647\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgOXu75irDVk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0691a1d2-46b4-4382-ac2f-2ebb0642bf9d"
      },
      "source": [
        "print(label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f1c80622400>, {'positive': 0, 'neutral': 1, 'negative': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsd_C2RKQLer",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = 64\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iter, valid_iter = data.BucketIterator.splits(\n",
        "    (train_data, valid_data),\n",
        "    batch_size = batches,\n",
        "    sort_within_batch = True,\n",
        "    sort_key= lambda x: len(x.text),\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIHRDnqlqodQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN_LSTM(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_dim, hid_dim, op_dim, n_layers, bidirect, drop, pad_idx):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx = pad_idx)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hid_dim,\n",
        "                      num_layers = n_layers,\n",
        "                      bidirectional = bidirect,\n",
        "                      dropout  = 0 if n_layers < 2 else drop)\n",
        "    self.fc = nn.Linear(hidden_dim * 2 if bidirect else hidden_dim, op_dim) \n",
        "    # self.fc = nn.Linear(hidden_dim * 2 if bidirect else hidden_dim, hidden_dim if bidirect else hidden_dim/2)\n",
        "    # self.fc2 = nn.Linear(hidden_dim if bidirect else hidden_dim/2, op_dim)\n",
        "    self.dropout = nn.Dropout(drop)\n",
        "\n",
        "  def forward(self, text, text_lengths):\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "\n",
        "    #packed padding - when passing a batch all the inputs are of the same size \n",
        "    #                 so shorter sentences are padded with <pad> in the front. \n",
        "    #                 In packed padding while the padded input will be passed, \n",
        "    #                 the <pad> elements will output as 0 and only the non <pad> \n",
        "    #                 elements will affect the model\n",
        "\n",
        "    packed_embedded =nn.utils.rnn.pack_padded_sequence(embedded, text_lengths) \n",
        "    packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "\n",
        "    #unpacking sequence\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "    if self.rnn.bidirectional:\n",
        "      hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "    else:\n",
        "      hidden = self.dropout(hidden[-1,:,:])\n",
        "    \n",
        "    # hidden = self.fc(hidden)  \n",
        "\n",
        "    return self.fc(hidden)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gp_8P1StaDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(tweet.vocab)\n",
        "embedding_dim = 100\n",
        "hidden_dim = 256\n",
        "output_dim = len(label.vocab)\n",
        "n_layers = 2\n",
        "bi_dir = True\n",
        "dropout = 0.4\n",
        "pad_idx = tweet.vocab.stoi[tweet.pad_token]\n",
        "\n",
        "model = RNN_LSTM(input_dim, embedding_dim, \n",
        "            hidden_dim, output_dim,\n",
        "            n_layers, bi_dir,\n",
        "            dropout, pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl6AcoHEyIiD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68cc1725-0a9e-4f22-e014-2161aa13a97f"
      },
      "source": [
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 4,877,154 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZhVfpiW5Mza",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1cee9a4-26a8-493e-acf8-2b274ddd2724"
      },
      "source": [
        "pretrain_embed = tweet.vocab.vectors #GloVe vectors (100d)\n",
        "\n",
        "print(pretrain_embed.shape) # [vocab_len, 100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([25647, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCImdAKs5bfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d0d3c5bd-7526-4779-fd9f-edc1ff97d981"
      },
      "source": [
        "model.embedding.weight.data.copy_(pretrain_embed) #initialising model word embeddings with GloVe embeds\n",
        "\n",
        "#<unk> and <pad> are not in GloVe vocab so they are intialised randomly from a normal distribution"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1117, -0.4966,  0.1631,  ...,  1.2647, -0.2753, -0.1325],\n",
              "        [-0.8555, -0.7208,  1.3755,  ...,  0.0825, -1.1314,  0.3997],\n",
              "        [ 0.0952,  0.3702,  0.5429,  ..., -0.5108,  0.4688,  0.3488],\n",
              "        ...,\n",
              "        [-0.2369, -0.2940,  0.0918,  ..., -0.4967, -0.1751,  0.1848],\n",
              "        [ 0.1977,  0.1966,  0.3419,  ...,  0.1391,  0.3802,  0.6479],\n",
              "        [-0.9683,  0.7869,  1.5518,  ..., -0.2938,  1.3459, -0.7236]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDKMd1j85sWE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fcd9bd22-6b40-48a7-bfc5-fd6eee568375"
      },
      "source": [
        "unk_idx = tweet.vocab.stoi[tweet.unk_token]\n",
        "\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim) #setting <unk> embedding as zero to teach model that the token is irrelevant for sentiment analysis\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim) #setting <pad> embedding as zero to teach model that the token is irrelevant for sentiment analysis\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0952,  0.3702,  0.5429,  ..., -0.5108,  0.4688,  0.3488],\n",
            "        ...,\n",
            "        [-0.2369, -0.2940,  0.0918,  ..., -0.4967, -0.1751,  0.1848],\n",
            "        [ 0.1977,  0.1966,  0.3419,  ...,  0.1391,  0.3802,  0.6479],\n",
            "        [-0.9683,  0.7869,  1.5518,  ..., -0.2938,  1.3459, -0.7236]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvp_6tix6YUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim \n",
        "\n",
        "optimizer = optim.Adagrad(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HmIncr-FKfe_",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OsJ_Ra6K1Nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kdPvkLQFKffB",
        "colab": {}
      },
      "source": [
        "def calc_acc(preds, y):\n",
        "  max_preds = preds.argmax(dim=1, keepdim = True)\n",
        "  correct = max_preds.squeeze(1).eq(y)\n",
        "  return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHd0EVNzV3-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, text_lengths = batch.text\n",
        "    predictions = model(text, text_lengths).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = calc_acc(predictions, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYVSQArLW13U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      text, text_lengths = batch.text\n",
        "      predictions = model(text, text_lengths).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      acc = calc_acc(predictions, batch.label)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg8eTVuyXanY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time \n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_sec = int(elapsed_time - (elapsed_mins * 60))\n",
        "\n",
        "  return elapsed_mins, elapsed_sec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28iUkcyX2mM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "71d725d3-2743-4d81-b8c2-193a00646b62"
      },
      "source": [
        "num_epochs = 15 \n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'RNN_LSTM.pt')\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.882 | Train Acc: 56.86%\n",
            "\tVal. Loss: 0.811 | Val. Acc: 61.34%\n",
            "Epoch: 02 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.768 | Train Acc: 63.93%\n",
            "\tVal. Loss: 0.782 | Val. Acc: 63.27%\n",
            "Epoch: 03 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.717 | Train Acc: 67.46%\n",
            "\tVal. Loss: 0.768 | Val. Acc: 64.67%\n",
            "Epoch: 04 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.684 | Train Acc: 69.29%\n",
            "\tVal. Loss: 0.759 | Val. Acc: 65.34%\n",
            "Epoch: 05 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.650 | Train Acc: 70.97%\n",
            "\tVal. Loss: 0.770 | Val. Acc: 64.86%\n",
            "Epoch: 06 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.623 | Train Acc: 72.58%\n",
            "\tVal. Loss: 0.773 | Val. Acc: 65.17%\n",
            "Epoch: 07 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.603 | Train Acc: 73.57%\n",
            "\tVal. Loss: 0.764 | Val. Acc: 64.66%\n",
            "Epoch: 08 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.579 | Train Acc: 74.92%\n",
            "\tVal. Loss: 0.787 | Val. Acc: 64.79%\n",
            "Epoch: 09 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.555 | Train Acc: 76.04%\n",
            "\tVal. Loss: 0.777 | Val. Acc: 65.50%\n",
            "Epoch: 10 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.535 | Train Acc: 76.79%\n",
            "\tVal. Loss: 0.792 | Val. Acc: 64.95%\n",
            "Epoch: 11 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.515 | Train Acc: 78.33%\n",
            "\tVal. Loss: 0.820 | Val. Acc: 65.89%\n",
            "Epoch: 12 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.490 | Train Acc: 79.15%\n",
            "\tVal. Loss: 0.865 | Val. Acc: 65.41%\n",
            "Epoch: 13 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.472 | Train Acc: 79.78%\n",
            "\tVal. Loss: 0.825 | Val. Acc: 64.78%\n",
            "Epoch: 14 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.454 | Train Acc: 80.91%\n",
            "\tVal. Loss: 0.833 | Val. Acc: 65.17%\n",
            "Epoch: 15 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.444 | Train Acc: 81.77%\n",
            "\tVal. Loss: 0.868 | Val. Acc: 65.02%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgDSXljSRNC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "359f4b8e-5161-4657-81fe-55f711659727"
      },
      "source": [
        "test_data_path = \"/content/test_samples.txt\"\n",
        "\n",
        "test_tweets = pd.read_csv(test_data_path, sep=',')\n",
        "test_tweets.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264238274963451904</td>\n",
              "      <td>@jjuueellzz down in the Atlantic city, ventnor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>218775148495515649</td>\n",
              "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>258965201766998017</td>\n",
              "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262926411352903682</td>\n",
              "      <td>Kapan sih lo ngebuktiin,jan ngomong doang Susa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171874368908050432</td>\n",
              "      <td>Excuse the connectivity of this live stream, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>256010056942903296</td>\n",
              "      <td>Show your LOVE for your local field &amp; it might...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>253809989599232000</td>\n",
              "      <td>Milton on Bolton Wanderers 2 v 2 Leeds United,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>261776619146985472</td>\n",
              "      <td>@firecore Can you tell me when an update for t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>264143999374356481</td>\n",
              "      <td>@Heavensbasement The Crown, Filthy McNastys, K...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>223052929131757571</td>\n",
              "      <td>Uncover the Eternal City! Return flights to Ro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id                                         tweet_text\n",
              "0  264238274963451904  @jjuueellzz down in the Atlantic city, ventnor...\n",
              "1  218775148495515649  Musical awareness: Great Big Beautiful Tomorro...\n",
              "2  258965201766998017  On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...\n",
              "3  262926411352903682  Kapan sih lo ngebuktiin,jan ngomong doang Susa...\n",
              "4  171874368908050432  Excuse the connectivity of this live stream, f...\n",
              "5  256010056942903296  Show your LOVE for your local field & it might...\n",
              "6  253809989599232000  Milton on Bolton Wanderers 2 v 2 Leeds United,...\n",
              "7  261776619146985472  @firecore Can you tell me when an update for t...\n",
              "8  264143999374356481  @Heavensbasement The Crown, Filthy McNastys, K...\n",
              "9  223052929131757571  Uncover the Eternal City! Return flights to Ro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXHqdz1ShHVa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3f815c1-d52e-45cc-d34d-4869734abbee"
      },
      "source": [
        "test_tweets[\"cleaned_test_tweet\"] = cleaning_tweets(test_tweets.loc[:,\"tweet_text\"])\n",
        "test_tweets.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cleaned_test_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264238274963451904</td>\n",
              "      <td>@jjuueellzz down in the Atlantic city, ventnor...</td>\n",
              "      <td>down in the atlantic city ventnor margate oce...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>218775148495515649</td>\n",
              "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
              "      <td>musical awareness great big beautiful tomorrow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>258965201766998017</td>\n",
              "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
              "      <td>on radio fm  fri oct  labour analyst shawn hat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262926411352903682</td>\n",
              "      <td>Kapan sih lo ngebuktiin,jan ngomong doang Susa...</td>\n",
              "      <td>kapan sih lo ngebuktiinjan ngomong doang susah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171874368908050432</td>\n",
              "      <td>Excuse the connectivity of this live stream, f...</td>\n",
              "      <td>excuse the connectivity of this live stream fr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ...                                 cleaned_test_tweet\n",
              "0  264238274963451904  ...   down in the atlantic city ventnor margate oce...\n",
              "1  218775148495515649  ...  musical awareness great big beautiful tomorrow...\n",
              "2  258965201766998017  ...  on radio fm  fri oct  labour analyst shawn hat...\n",
              "3  262926411352903682  ...  kapan sih lo ngebuktiinjan ngomong doang susah...\n",
              "4  171874368908050432  ...  excuse the connectivity of this live stream fr...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLOxGvXrhgN1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "444be5b6-d235-49fa-b2ff-d8ea274fbdbd"
      },
      "source": [
        "test_df = test_tweets.loc[:,[\"tweet_id\",\"cleaned_test_tweet\"]]\n",
        "\n",
        "test_data = DataFrameDataset(\n",
        "    df=test_df, \n",
        "    fields=(\n",
        "        ('id', id),\n",
        "        ('text', tweet)\n",
        "    )\n",
        ")\n",
        "\n",
        "print(len(test_data))\n",
        "print(vars(test_data.examples[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5398\n",
            "{'id': 264238274963451904, 'text': ['down', 'in', 'the', 'atlantic', 'city', 'ventnor', 'margate', 'ocean', 'city', 'area', 'im', 'just', 'waiting', 'for', 'the', 'coordinator', 'to', 'hopefully', 'call', 'me', 'tomorrow']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgs5PFmBlZcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a554587-906b-47bb-b551-d20ab93e2ec8"
      },
      "source": [
        "model.load_state_dict(torch.load('RNN_LSTM.pt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDB3ANMRlQgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_class(model, tokens):\n",
        "    model.eval()\n",
        "    indexed = [tweet.vocab.stoi[t] for t in tokens]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    preds = model(tensor, length_tensor)\n",
        "    max_preds = preds.argmax(dim = 1)\n",
        "    return max_preds.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye4lU-4bpkbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb99500b-7804-44ee-a4cc-7b7ae1dfbfc3"
      },
      "source": [
        "pred_class = predict_class(model, \"the movie is about a tiger\".split())\n",
        "print(pred_class)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci9ROVOHtnPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51a95f1f-3986-4409-8b84-7e15658697fb"
      },
      "source": [
        "labels = dict(label.vocab.stoi)\n",
        "\n",
        "labels_idx = {labels[lab]:lab for lab in labels.keys()}\n",
        "print(labels_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'positive', 1: 'neutral', 2: 'negative'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBKLUfkPvAgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "e66d14c6-73a6-4b12-c49d-c85638a6b937"
      },
      "source": [
        "test_tweets[\"pred_label\"] = [predict_class(model, vars(test_data.examples[i])['text']) for i in range(len(test_data))]\n",
        "\n",
        "test_tweets.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cleaned_test_tweet</th>\n",
              "      <th>pred_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264238274963451904</td>\n",
              "      <td>@jjuueellzz down in the Atlantic city, ventnor...</td>\n",
              "      <td>down in the atlantic city ventnor margate oce...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>218775148495515649</td>\n",
              "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
              "      <td>musical awareness great big beautiful tomorrow...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>258965201766998017</td>\n",
              "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
              "      <td>on radio fm  fri oct  labour analyst shawn hat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262926411352903682</td>\n",
              "      <td>Kapan sih lo ngebuktiin,jan ngomong doang Susa...</td>\n",
              "      <td>kapan sih lo ngebuktiinjan ngomong doang susah...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171874368908050432</td>\n",
              "      <td>Excuse the connectivity of this live stream, f...</td>\n",
              "      <td>excuse the connectivity of this live stream fr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>256010056942903296</td>\n",
              "      <td>Show your LOVE for your local field &amp; it might...</td>\n",
              "      <td>show your love for your local field  it might ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>253809989599232000</td>\n",
              "      <td>Milton on Bolton Wanderers 2 v 2 Leeds United,...</td>\n",
              "      <td>milton on bolton wanderers  v  leeds united sa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>261776619146985472</td>\n",
              "      <td>@firecore Can you tell me when an update for t...</td>\n",
              "      <td>can you tell me when an update for the apple ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>264143999374356481</td>\n",
              "      <td>@Heavensbasement The Crown, Filthy McNastys, K...</td>\n",
              "      <td>the crown filthy mcnastys katy dalys or the d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>223052929131757571</td>\n",
              "      <td>Uncover the Eternal City! Return flights to Ro...</td>\n",
              "      <td>uncover the eternal city return flights to rom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ... pred_label\n",
              "0  264238274963451904  ...          1\n",
              "1  218775148495515649  ...          0\n",
              "2  258965201766998017  ...          1\n",
              "3  262926411352903682  ...          1\n",
              "4  171874368908050432  ...          1\n",
              "5  256010056942903296  ...          0\n",
              "6  253809989599232000  ...          1\n",
              "7  261776619146985472  ...          1\n",
              "8  264143999374356481  ...          0\n",
              "9  223052929131757571  ...          1\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiN79Wc6wsEs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "30ed4853-9507-4cc5-b8dd-1a5e87bb6459"
      },
      "source": [
        "test_tweets[\"sentiment\"] = [labels_idx[idx] for idx in test_tweets.loc[:,\"pred_label\"]]\n",
        "\n",
        "test_tweets.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>cleaned_test_tweet</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264238274963451904</td>\n",
              "      <td>@jjuueellzz down in the Atlantic city, ventnor...</td>\n",
              "      <td>down in the atlantic city ventnor margate oce...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>218775148495515649</td>\n",
              "      <td>Musical awareness: Great Big Beautiful Tomorro...</td>\n",
              "      <td>musical awareness great big beautiful tomorrow...</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>258965201766998017</td>\n",
              "      <td>On Radio786 100.4fm 7:10 Fri Oct 19 Labour ana...</td>\n",
              "      <td>on radio fm  fri oct  labour analyst shawn hat...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262926411352903682</td>\n",
              "      <td>Kapan sih lo ngebuktiin,jan ngomong doang Susa...</td>\n",
              "      <td>kapan sih lo ngebuktiinjan ngomong doang susah...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171874368908050432</td>\n",
              "      <td>Excuse the connectivity of this live stream, f...</td>\n",
              "      <td>excuse the connectivity of this live stream fr...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>256010056942903296</td>\n",
              "      <td>Show your LOVE for your local field &amp; it might...</td>\n",
              "      <td>show your love for your local field  it might ...</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>253809989599232000</td>\n",
              "      <td>Milton on Bolton Wanderers 2 v 2 Leeds United,...</td>\n",
              "      <td>milton on bolton wanderers  v  leeds united sa...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>261776619146985472</td>\n",
              "      <td>@firecore Can you tell me when an update for t...</td>\n",
              "      <td>can you tell me when an update for the apple ...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>264143999374356481</td>\n",
              "      <td>@Heavensbasement The Crown, Filthy McNastys, K...</td>\n",
              "      <td>the crown filthy mcnastys katy dalys or the d...</td>\n",
              "      <td>0</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>223052929131757571</td>\n",
              "      <td>Uncover the Eternal City! Return flights to Ro...</td>\n",
              "      <td>uncover the eternal city return flights to rom...</td>\n",
              "      <td>1</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id  ... sentiment\n",
              "0  264238274963451904  ...   neutral\n",
              "1  218775148495515649  ...  positive\n",
              "2  258965201766998017  ...   neutral\n",
              "3  262926411352903682  ...   neutral\n",
              "4  171874368908050432  ...   neutral\n",
              "5  256010056942903296  ...  positive\n",
              "6  253809989599232000  ...   neutral\n",
              "7  261776619146985472  ...   neutral\n",
              "8  264143999374356481  ...  positive\n",
              "9  223052929131757571  ...   neutral\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8lsDsXexP05",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "d3c1ce09-f9e5-40a9-d91f-2a176f69e614"
      },
      "source": [
        "final_df = test_tweets.loc[:,[\"tweet_id\", \"sentiment\"]]\n",
        "\n",
        "final_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>264238274963451904</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>218775148495515649</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>258965201766998017</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>262926411352903682</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>171874368908050432</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>256010056942903296</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>253809989599232000</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>261776619146985472</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>264143999374356481</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>223052929131757571</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             tweet_id sentiment\n",
              "0  264238274963451904   neutral\n",
              "1  218775148495515649  positive\n",
              "2  258965201766998017   neutral\n",
              "3  262926411352903682   neutral\n",
              "4  171874368908050432   neutral\n",
              "5  256010056942903296  positive\n",
              "6  253809989599232000   neutral\n",
              "7  261776619146985472   neutral\n",
              "8  264143999374356481  positive\n",
              "9  223052929131757571   neutral"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwpoZuHKxYhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_df.to_csv(\"HrishitaC_IITK_NLP.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-bMEs_LwMh0",
        "colab_type": "text"
      },
      "source": [
        "#Model 3: CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5lfej30wL3C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "698a632c-4725-4de0-83a0-37533e75dc6d"
      },
      "source": [
        "df = tweet_data.loc[:,['cleaned_tweet', 'sentiment']]\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gas house hit going chapel hill sat happy</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>theo walcott still shit watch rafa johnny deal...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not gsp fan hate nick diaz cant wait february</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iranian general says israels iron dome cant de...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tehran mon amour obama tried establish ties mu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sat whole movie harry ron christmas ohlawd</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>davlar main rivals team poland hopefully make ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>talking acts sats deciding want college applyi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>why happy valentines day trending its february...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>they may superbowl dallas dallas aint winning ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       cleaned_tweet sentiment\n",
              "0          gas house hit going chapel hill sat happy  positive\n",
              "1  theo walcott still shit watch rafa johnny deal...  negative\n",
              "2      not gsp fan hate nick diaz cant wait february  negative\n",
              "3  iranian general says israels iron dome cant de...  negative\n",
              "4  tehran mon amour obama tried establish ties mu...   neutral\n",
              "5         sat whole movie harry ron christmas ohlawd   neutral\n",
              "6  davlar main rivals team poland hopefully make ...  positive\n",
              "7  talking acts sats deciding want college applyi...  negative\n",
              "8  why happy valentines day trending its february...   neutral\n",
              "9  they may superbowl dallas dallas aint winning ...  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZWVD2k5q6fXv",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyNZizXAQIzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet = data.Field(tokenize = 'spacy')\n",
        "label = data.LabelField()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QRGSjoLq6fX2",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Dataset, Example\n",
        "import pandas as pd\n",
        "\n",
        "# Torchtext does not have any inherit method to deal with dataframes\n",
        "# as input data, hence we create a child class of Dataset class  \n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_FrSbZbwV8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, valid_data = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', tweet),\n",
        "        ('label', label)\n",
        "    )\n",
        ").split(split_ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnJFJFZf6v1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "71eec5ba-0702-4ccd-9470-4a5f51b56efa"
      },
      "source": [
        "print(vars(train_data[0]))\n",
        "print(vars(valid_data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': ['career', 'fair', 'tomorrow', 'murphy', 'center', 'dress', 'business', 'attire', 'bring', 'resumes'], 'label': 'neutral'}\n",
            "{'text': ['ill', 'share', 'care', 'clud', 'weird', 'crush', 'justin', 'sororithank', 'you', 'gin', 'real', 'life', 'comes', 'across', 'turn'], 'label': 'negative'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FE1z2VrL64C-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_vocab_size = 25000\n",
        "\n",
        "tweet.build_vocab(train_data,\n",
        "                  max_size = max_vocab_size,\n",
        "                  vectors = \"glove.twitter.27B.100d\",\n",
        "                  unk_init = torch.Tensor.normal_)\n",
        "\n",
        "label.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0ZDOVnYCbLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65583990-143d-4b56-f935-3a17439defc3"
      },
      "source": [
        "print(len(tweet.vocab))\n",
        "print(len(label.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25002\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNUTN1m57UC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b45bb2e-9dc8-4630-b2b2-124af5188ee1"
      },
      "source": [
        "print(label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fd91c97fea0>, {'positive': 0, 'neutral': 1, 'negative': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gc0PYCwJ7Wgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batches = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iter, valid_iter = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = batches, \n",
        "    sort_within_batch = True,\n",
        "    sort_key= lambda x: len(x.text),\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIpZsaJs7waE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, vocab_size, emb_dim, n_filters, filter_sizes,\n",
        "               op_dim, drop, \n",
        "              #  pad,\n",
        "               pad_idx):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx = pad_idx)\n",
        "    # self.pad = nn.ZeroPad2d((0,0,pad,pad)) #(left, right, top, bottom)\n",
        "    self.convs = nn.ModuleList([\n",
        "                                nn.Conv2d(in_channels = 1,\n",
        "                                          out_channels = n_filters,\n",
        "                                          kernel_size = (fs, emb_dim))\n",
        "                                for fs in filter_sizes\n",
        "                                ]) \n",
        "    self.fc = nn.Linear(len(filter_sizes)*n_filters, op_dim)\n",
        "    self.dropout = nn.Dropout(drop)\n",
        "\n",
        "  def forward(self, text):\n",
        "    text = text.permute(1, 0)\n",
        "    embedded = self.embedding(text)\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    # if pad > 0:\n",
        "    #   embedded = self.pad(embedded)\n",
        "    conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    cat = self.dropout(torch.cat(pooled, dim=1))\n",
        "\n",
        "    return self.fc(cat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a-u5qIv9YwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = len(tweet.vocab)\n",
        "embedding_dim = 100\n",
        "n_filters = 100\n",
        "filter_sizes = [2, 3, 4]\n",
        "op_dim = len(label.vocab)\n",
        "dropout = 0.4\n",
        "# padding = 0\n",
        "pad_idx = tweet.vocab.stoi[tweet.pad_token]\n",
        "\n",
        "model = CNN(input_dim, embedding_dim, n_filters, filter_sizes, op_dim, dropout, \n",
        "            # padding, \n",
        "            pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxNgkFPL9xL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a479543c-3181-46d7-f411-001b4da83310"
      },
      "source": [
        "def count_params(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_params(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,591,403 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQt3Ydjt-DfI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "932da393-f9c3-45b3-db92-e7c71ff3454c"
      },
      "source": [
        "pretrained_emb = tweet.vocab.vectors\n",
        "\n",
        "model.embedding.weight.data.copy_(pretrained_emb)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.2501,  0.4024,  0.9963,  ...,  1.2980,  0.1232,  0.4092],\n",
              "        [-1.7404,  0.3036,  0.0273,  ..., -1.2587,  0.2789,  0.5907],\n",
              "        [-0.5093,  0.2515,  0.1390,  ...,  0.7849, -0.3699, -0.4106],\n",
              "        ...,\n",
              "        [-1.1484,  1.1011, -0.5901,  ..., -0.0772,  0.0206,  1.3303],\n",
              "        [-0.4908,  1.1556, -0.1981,  ...,  0.6285, -0.5695, -0.0437],\n",
              "        [ 0.8661,  0.2620,  0.7279,  ..., -0.7392,  0.1248,  0.5263]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qnHJ9Zj-K8t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unk_idx = tweet.vocab.stoi[tweet.unk_token]\n",
        "\n",
        "model.embedding.weight.data[unk_idx] = torch.zeros(embedding_dim)\n",
        "model.embedding.weight.data[pad_idx] = torch.zeros(embedding_dim)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txKPJi5P-W7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kE1sTV3-kz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_acc(preds, y):\n",
        "  max_preds = preds.argmax(dim=1, keepdim = True)\n",
        "  correct = max_preds.squeeze(1).eq(y)\n",
        "  return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aihYIm3_FA2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = calc_acc(predictions, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc/len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1rNf5kA_nr7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      predictions = model(batch.text)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      acc = calc_acc(predictions, batch.label)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U0Ll1X9AIao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - elapsed_mins * 60)\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pdmzo-OAaos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1dff8d98-5fc1-4aa8-9e6b-b1adcb772ed4"
      },
      "source": [
        "epochs = 20\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'phase-4.pt')\n",
        "\n",
        "  print(f'Epoch {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 01 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.885 | Train Acc: 56.12%\n",
            "\tVal. Loss: 0.784 | Val. Acc: 64.14%\n",
            "Epoch 02 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.716 | Train Acc: 67.77%\n",
            "\tVal. Loss: 0.746 | Val. Acc: 66.46%\n",
            "Epoch 03 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.584 | Train Acc: 75.77%\n",
            "\tVal. Loss: 0.787 | Val. Acc: 65.40%\n",
            "Epoch 04 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.457 | Train Acc: 81.62%\n",
            "\tVal. Loss: 0.832 | Val. Acc: 64.94%\n",
            "Epoch 05 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.330 | Train Acc: 87.39%\n",
            "\tVal. Loss: 0.949 | Val. Acc: 63.73%\n",
            "Epoch 06 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.232 | Train Acc: 91.69%\n",
            "\tVal. Loss: 1.070 | Val. Acc: 62.85%\n",
            "Epoch 07 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.170 | Train Acc: 94.19%\n",
            "\tVal. Loss: 1.202 | Val. Acc: 62.00%\n",
            "Epoch 08 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.114 | Train Acc: 96.39%\n",
            "\tVal. Loss: 1.381 | Val. Acc: 61.89%\n",
            "Epoch 09 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.084 | Train Acc: 97.46%\n",
            "\tVal. Loss: 1.486 | Val. Acc: 61.73%\n",
            "Epoch 10 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.068 | Train Acc: 98.01%\n",
            "\tVal. Loss: 1.626 | Val. Acc: 61.98%\n",
            "Epoch 11 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.055 | Train Acc: 98.48%\n",
            "\tVal. Loss: 1.783 | Val. Acc: 61.22%\n",
            "Epoch 12 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.050 | Train Acc: 98.51%\n",
            "\tVal. Loss: 1.885 | Val. Acc: 60.56%\n",
            "Epoch 13 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.042 | Train Acc: 98.82%\n",
            "\tVal. Loss: 2.000 | Val. Acc: 61.04%\n",
            "Epoch 14 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.037 | Train Acc: 99.06%\n",
            "\tVal. Loss: 2.131 | Val. Acc: 61.25%\n",
            "Epoch 15 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.034 | Train Acc: 99.04%\n",
            "\tVal. Loss: 2.227 | Val. Acc: 60.60%\n",
            "Epoch 16 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.031 | Train Acc: 99.16%\n",
            "\tVal. Loss: 2.343 | Val. Acc: 60.95%\n",
            "Epoch 17 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.028 | Train Acc: 99.31%\n",
            "\tVal. Loss: 2.373 | Val. Acc: 60.63%\n",
            "Epoch 18 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.029 | Train Acc: 99.33%\n",
            "\tVal. Loss: 2.497 | Val. Acc: 60.65%\n",
            "Epoch 19 | Epoch Time: 0m 2s\n",
            "\tTrain Loss: 0.027 | Train Acc: 99.38%\n",
            "\tVal. Loss: 2.602 | Val. Acc: 60.53%\n",
            "Epoch 20 | Epoch Time: 0m 1s\n",
            "\tTrain Loss: 0.025 | Train Acc: 99.36%\n",
            "\tVal. Loss: 2.729 | Val. Acc: 59.75%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C32-A5SBy1i",
        "colab_type": "text"
      },
      "source": [
        "Phase4: Val Accuracy: 64.27%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6BOT7702yeR",
        "colab_type": "text"
      },
      "source": [
        "#Model 4: Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "584CBRbWplc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "1b8cd21a-765d-4dfe-b1ba-1392f89460d6"
      },
      "source": [
        "df = tweet_data.loc[:,['cleaned_tweet', 'sentiment']]\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_tweet</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gas house hit going chapel hill sat happy</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>theo walcott still shit watch rafa johnny deal...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not gsp fan hate nick diaz cant wait february</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>iranian general says israels iron dome cant de...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tehran mon amour obama tried establish ties mu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>sat whole movie harry ron christmas ohlawd</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>davlar main rivals team poland hopefully make ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>talking acts sats deciding want college applyi...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>why happy valentines day trending its february...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>they may superbowl dallas dallas aint winning ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       cleaned_tweet sentiment\n",
              "0          gas house hit going chapel hill sat happy  positive\n",
              "1  theo walcott still shit watch rafa johnny deal...  negative\n",
              "2      not gsp fan hate nick diaz cant wait february  negative\n",
              "3  iranian general says israels iron dome cant de...  negative\n",
              "4  tehran mon amour obama tried establish ties mu...   neutral\n",
              "5         sat whole movie harry ron christmas ohlawd   neutral\n",
              "6  davlar main rivals team poland hopefully make ...  positive\n",
              "7  talking acts sats deciding want college applyi...  negative\n",
              "8  why happy valentines day trending its february...   neutral\n",
              "9  they may superbowl dallas dallas aint winning ...  negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XopbCHUyplc8",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir5gesdxqJp-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "f598cc1c-624f-4ca6-b72e-0ffb11e22282"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
            "\r\u001b[K     |▍                               | 10kB 7.5MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 4.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 6.2MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 81kB 6.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 92kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 102kB 6.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 133kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 153kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 163kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 174kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 184kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 194kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 204kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 215kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 225kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 235kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 245kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 256kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 266kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 276kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 286kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 296kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 307kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 317kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 327kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 337kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 348kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 358kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 368kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 378kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 389kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 399kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 409kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 419kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 430kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 440kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 450kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 460kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 471kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 481kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 491kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 501kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 512kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 522kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 532kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 542kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 552kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 563kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 573kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 583kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 593kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 604kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 614kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 624kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 634kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 645kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 655kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 665kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 675kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 686kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 696kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 706kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 716kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 727kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 737kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 747kB 6.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 757kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 768kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 778kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 18.1MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 36.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 40.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=6a8dc43228b31cf5949dab8324583067b5ea55d24e041af7adac3452f197d585\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAFMmxUapuds",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "07de4e707cf24210949dbb346913ccff",
            "eb96de0b40484d9e96b1268059fabdd1",
            "9cf5428acc5b440fad4f555607f2c289",
            "e8dc6b9a595440fea188da0133498b88",
            "809e8390149945da8b7a966214396970",
            "931b4350bd224508981cb0db6ced7d19",
            "9f043c4319bf4def8d14a17ba00c4b36",
            "d62a48f24ba74c60832d2c1b8babf7a3"
          ]
        },
        "outputId": "e0075d91-5f48-46ed-ccdc-5ed9b9ac6946"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07de4e707cf24210949dbb346913ccff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tZtRyh9qTMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e1ea721a-faa1-4512-9674-2a66658d26d7"
      },
      "source": [
        "len(tokenizer.vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-4N10ArrG0a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da8bc5dc-25f7-4f12-d318-bdd881408e0c"
      },
      "source": [
        "init_token = tokenizer.cls_token # beginning of a sentence token\n",
        "eos_token = tokenizer.sep_token # end of sentence token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uza87vnBsLJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fc66695-b0ad-432a-a2ae-277f23932798"
      },
      "source": [
        "init_token_idx = tokenizer.cls_token_id\n",
        "eos_token_idx = tokenizer.sep_token_id\n",
        "pad_token_idx = tokenizer.pad_token_id\n",
        "unk_token_idx = tokenizer.unk_token_id\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EqQX1i6q0CN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc064f6b-1ce9-4069-f28f-a4602dbc6cb9"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "print(max_input_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCUDRCHlqs8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize_and_cut(sentence):\n",
        "  tokens = tokenizer.tokenize(sentence)\n",
        "  tokens = tokens[:max_input_length - 2] # we subtract two because we need to make space for [CLS] and [SEP] token\n",
        "  return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O3HPeSABplc-",
        "colab": {}
      },
      "source": [
        "tweet = data.Field(batch_first = True,\n",
        "                   use_vocab = False,\n",
        "                   tokenize = tokenize_and_cut,\n",
        "                   preprocessing = tokenizer.convert_tokens_to_ids,\n",
        "                   init_token = init_token_idx,\n",
        "                   eos_token = eos_token_idx,\n",
        "                   pad_token = pad_token_idx,\n",
        "                   unk_token = unk_token_idx)\n",
        "\n",
        "label = data.LabelField()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVMezRdYplc_",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Dataset, Example\n",
        "import pandas as pd\n",
        "\n",
        "# Torchtext does not have any inherit method to deal with dataframes\n",
        "# as input data, hence we create a child class of Dataset class  \n",
        "\n",
        "class DataFrameDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, fields: list):\n",
        "        super(DataFrameDataset, self).__init__(\n",
        "            [\n",
        "                Example.fromlist(list(r), fields) \n",
        "                for i, r in df.iterrows()\n",
        "            ], \n",
        "            fields\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vlPE1H95pldD",
        "colab": {}
      },
      "source": [
        "train_data, valid_data = DataFrameDataset(\n",
        "    df=df, \n",
        "    fields=(\n",
        "        ('text', tweet),\n",
        "        ('label', label)\n",
        "    )\n",
        ").split(split_ratio=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CwxR_a4wpldF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "711d0196-5fec-4e68-8b71-e30b85909f11"
      },
      "source": [
        "print(vars(train_data[0]))\n",
        "print(vars(valid_data[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'text': [2388, 3336, 2938, 26220, 22012, 15854, 8248, 4476], 'label': 'positive'}\n",
            "{'text': [2215, 3422, 2108, 2529, 1998, 2438, 2769, 4965, 3482, 13462, 2237, 4826, 2004, 20952, 5603, 15992, 2140], 'label': 'neutral'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eu8rviattDZq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc7a4317-3456-4620-d967-2966ff241925"
      },
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(vars(train_data[0])['text'])\n",
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mother', 'baby', 'sat', 'ric', 'flair', 'woo', 'brush', 'fame']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KLbJ0XWBpldH",
        "colab": {}
      },
      "source": [
        "# max_vocab_size = 25000\n",
        "\n",
        "# tweet.build_vocab(train_data,\n",
        "#                   max_size = max_vocab_size,\n",
        "#                   vectors = \"glove.twitter.27B.100d\",\n",
        "#                   unk_init = torch.Tensor.normal_)\n",
        "\n",
        "label.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FAVRKc36pldJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e6976c12-c007-4f4d-f1f6-5580bfcd2a21"
      },
      "source": [
        "# print(len(tweet.vocab))\n",
        "print(len(label.vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RpNLI1vkpldK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ceeb7aef-07d2-4dca-8c4e-06a24fc25b0c"
      },
      "source": [
        "print(label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f6f53a0b268>, {'neutral': 0, 'positive': 1, 'negative': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z7K3Y_B9pldM",
        "colab": {}
      },
      "source": [
        "batches = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iter, valid_iter = data.BucketIterator.splits(\n",
        "    (train_data, valid_data), \n",
        "    batch_size = batches, \n",
        "    sort_within_batch = True,\n",
        "    sort_key= lambda x: len(x.text),\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKV1xflZptLT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "cb58a4e5f7a84df8ab6284b2b0195f73",
            "ae13b50d861345198a4f9dbc7a67cc33",
            "180d36bb81ea4a8f8d91a74d1026bce0",
            "b0112b629b5e4d65af74e93a8b67564f",
            "0677de77fe6b41e681f72d3f01058f88",
            "1be6303ca07f4f44b6c4afc522606a70",
            "753ee99e8f464d7980685ee01475b789",
            "147acac239124caaa8255c299c69a732",
            "b60b8717184d4316b85c0f589f2c0852",
            "3555afcc5f674c17ac908d7fb57cdb51",
            "59783fee81df475397fbb470bed3ce03",
            "3a198cd973c64ecf9643ab8d519fe4db",
            "35ce995315e245509c6c2c02cbab0224",
            "5cc7a03f8b50482b8780100a2210b664",
            "fb01d4aa75214b54a695dc04715131ad",
            "2539b02b9a8345d9ba86864740667b9b"
          ]
        },
        "outputId": "6276461e-0b8d-48a6-a3d1-cbdd5339a8a8"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb58a4e5f7a84df8ab6284b2b0195f73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b60b8717184d4316b85c0f589f2c0852",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gW53BTVuvW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTGRUSentiment(nn.Module):\n",
        "  def __init__ (self, bert, hidden_dim, op_dim, n_layers, bidirectional, dropout):\n",
        "    super().__init__()\n",
        "\n",
        "    self.bert = bert # instead of creating and training the word embeddings we use the pretrained BERT embeddings\n",
        "    embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "    self.rnn = nn.GRU(embedding_dim, hidden_dim,\n",
        "                      num_layers = n_layers,\n",
        "                      bidirectional = bidirectional,\n",
        "                      batch_first = True,\n",
        "                      dropout  = 0 if n_layers < 2 else dropout) \n",
        "    self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, op_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text):\n",
        "    with torch.no_grad():\n",
        "      embedded = self.bert(text)[0] #no training to be done in embedding layer\n",
        "    _, hidden = self.rnn(embedded)\n",
        "    if self.rnn.bidirectional:\n",
        "      hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "    else:\n",
        "      hidden = self.dropout(hidden[-1,:,:])\n",
        "\n",
        "    output = self.out(hidden)\n",
        "\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irmphfFkHd9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden_dim = 256\n",
        "output_dim = len(label.vocab)\n",
        "n_layers = 2\n",
        "bidirectional = True\n",
        "dropout = 0.25\n",
        "\n",
        "model = BERTGRUSentiment(bert, hidden_dim, output_dim, n_layers,\n",
        "                         bidirectional, dropout)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbeKRIwyIZAi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e8ba79e-9dbb-42f9-9bfe-dd0e6986768a"
      },
      "source": [
        "def count_params(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The unfrozen model has {count_params(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The unfrozen model has 112,242,435 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PakwRBnpIt4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  if name.startswith('bert'):\n",
        "    param.requires_grad = False # freezing all the BERT transformers params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2L5LOmuI77K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "495248a7-4e80-4e03-f708-0a2998aac77b"
      },
      "source": [
        "def count_params(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The frozen model has {count_params(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The frozen model has 2,760,195 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvybpwY-JABd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "25609b27-0a55-49d4-c6c4-64561e9e5103"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q2WhvSeODG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xCf7QNUOMTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NTCUhkSORSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9DmJbbLOWrQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_acc(preds, y):\n",
        "  max_preds = preds.argmax(dim=1, keepdim = True)\n",
        "  correct = max_preds.squeeze(1).eq(y)\n",
        "  return correct.sum() / torch.FloatTensor([y.shape[0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxRGp5VIOfqK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    predictions = model(batch.text).squeeze(1)\n",
        "    loss = criterion(predictions, batch.label)\n",
        "    acc = calc_acc(predictions, batch.label)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jl5dV-NhPOqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      predictions = model(batch.text).squeeze(1)\n",
        "      loss = criterion(predictions, batch.label)\n",
        "      acc = calc_acc(predictions, batch.label)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05PiRBQGPfiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "  elapsed_time = end_time - start_time\n",
        "  elapsed_mins = int(elapsed_time / 60)\n",
        "  elapsed_secs = int(elapsed_time - elapsed_mins*60)\n",
        "\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofTEQLw8FeRC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "5d2d391b-94ae-47b1-ff16-dda65c7a23ca"
      },
      "source": [
        "epochs = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'phase-5.pt')\n",
        "\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 57s\n",
            "\tTrain Loss: 0.694 | Train Acc: 68.98%\n",
            "\tVal. Loss: 0.815 | Val. Acc: 63.12%\n",
            "Epoch: 02 | Epoch Time: 0m 56s\n",
            "\tTrain Loss: 0.634 | Train Acc: 71.91%\n",
            "\tVal. Loss: 0.845 | Val. Acc: 62.55%\n",
            "Epoch: 03 | Epoch Time: 0m 56s\n",
            "\tTrain Loss: 0.588 | Train Acc: 74.46%\n",
            "\tVal. Loss: 0.887 | Val. Acc: 62.34%\n",
            "Epoch: 04 | Epoch Time: 0m 56s\n",
            "\tTrain Loss: 0.526 | Train Acc: 77.79%\n",
            "\tVal. Loss: 1.006 | Val. Acc: 60.69%\n",
            "Epoch: 05 | Epoch Time: 0m 57s\n",
            "\tTrain Loss: 0.502 | Train Acc: 79.58%\n",
            "\tVal. Loss: 0.965 | Val. Acc: 61.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofU7oLrEGdlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}